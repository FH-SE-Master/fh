

\chapter{Klassifikation}\label{Klassifikation}
\section{Einführung}
Bei der Klassifikation werden große Datensätze in Klassen eingeteilt und können durch die Anwendung von \nameref{Clustering} weiterverarbeitet werden. Diese Methoden erlauben es komplexe Daten  weiterzuverarbeiten. Durch diese Schritt wird eine Erweiterung der Anwendungsbereiche ermöglicht, da  bereits eingeteilte Daten einfacher zu bearbeiten und zu analysieren sind. Die Klassifikation ist ein Teil von Data Mining und Heuristik.\\
Im Gegensatz zum Clustering ist die Klassifikation eine Methode, welche anhand vorgegebener Trainingsdaten, die Auswahl des richtigen Algorithmus zu erleichtern. Die Zuordnung erfolgt dabei händisch. Damit lassen sich unbekannte Daten mit bestimmten Testdaten und Merkmalen eindeutig in Klassen einteilen. Dabei sind die Klassen und Trainingsdaten vorher bekannt und dies wird auch als überwachtes Lernen bezeichnet. \cite {mitch97}\\
Bevor mit der Klassifikation begonnen werden kann, müssen die Voraussetzungen definiert werden. Dabei wird von einer bestimmten Menge von Trainingsdaten ausgegangenen, welche bestimmte Merkmale bzw. Attribute aufweisen. Hier wird ein Klassentribut, welches die eindeutige Zuordnung zu einer bestimmten Klasse oder Gruppe besitzt  vorgegeben. Das Attribut für die Zuordnung ist immer qualitativ, die restlichen Merkmale können auch quantitativ sein.\cite {mitch97} \\

Diese Verfahren laufen in zwei Phasen ab. Dabei wird in der ersten Phase anhand dem Vorliegen der Daten, welche Trainingsdaten genannt werden, ein Klassenmodell aufgebaut. Dieses Modell wird in der zweiten Phase zur Zuordnung von den Daten angewandt. Das Klassenattribut ist an sich nicht bekannt um auch diese Daten in Klassen einzuteilen. Ziel der Klassifikation ist es anhand von vorgegeben Modellen  Daten zuordnen. \cite {mitch97}

\section{Klassifikationsgüte}
\subsection{Beschreibung}
Bei der Klassifikation ist das Einschätzen der Gütefunktion einfacher als beim Clustering. Da die Klassifikation die Objekte eindeutig zuordnen kann, ist es möglich die \textit{wahre Fehlerrate(true error rate)} zu berechnen und damit den Anteil der falsch klassifizierten Objekte zu bestimmen. Die textuelle mathematische Formel lautet: \\

\[\text{\textit{true error rate}} = \frac{\text{Anzahl der falsch klassifizierten Objekte}}{\text{Anzahl aller Objekte}}\]\\

Doch wenn sich unter den Daten unbekannte Objekte befinden, gibt es keine Methode die wahre Fehlerrate zu berechnen. Da keine Informationen über die Klassen vorhanden sind,  müssen andere Methoden gewählt werden, um eine etwaige Klassifikation zu bestimmen. Nur für die Trainingsdaten kann die wahre Fehlerrate \textit{a priori} bestimmt werden, da diese vor der Berechnung die Klassenzugehörigkeit bekannt ist. Die Fehlerrate für die Trainingsdaten wird \textit{offensichtliche Fehlerrate (apparent error rate)} genannt und lässt sich durch die folgende Formel beschreiben:\cite{mitch97}\\


\[\text{\textit{apperent error rate}} = \frac{\text{Anzahl der falsch klassifizierten Trainingsobjekte}}{\text{Anzahl aller Trainingsobjekte}}\]\\


In der Statistik wird häufig beschrieben, dass sich die offensichtliche Fehlerrate der wahren Fehlerrate annähert.  Wenn genügend Trainingsdaten vorhanden sind, kann die wahre Fehlerrate mit der offensichtlichen Fehlerrate gleich gesetzt werden und so mit die Fitness bzw. Gesundheit der realen Daten bestimmt werden. Bei der Betrachtung von realen Problemstellungen ist die Anzahl der Trainingsdaten kleiner und daher müssen Varianten und Verfahren gesucht werden, welche die wahre Fehlerrate annähernd berechnen können.\cite{weiss91}

\subsection{Train und Test}
Die einfachste Methode ist die Eingabedaten in zwei Teile zu teilen und den einen Teil als Trainingsdaten und den anderen Teil als Testmenge zu verwenden. Die Trainingsmenge wird angewandt um den Klassifikationsalgorithmus die vorgegeben Klassen mitzuteilen und damit dann die Testdaten zu klassifizieren. Die beiden Datensätze müssen unabhängig voneinander sein, da diese rein zufällig ausgewählt werden und damit kann die Fehlerrate recht gut angenähert werden. Die einzige Voraussetzung ist, dass die Testmenge relativ groß ist, da sonst die Klassifikation sehr schnell ungenau wird. Ansonsten muss auf andere Verfahren zurückgegriffen werden wie beispielsweise auf bestimmte Sampling Techniken. \cite{mitch97}\\
Auch andere Verfahren können die Klassifikationsgüte relativ gut aus dem Kontext des Anwendungsgebiets berechnen. Aber es ist es relativ schwer gute Ergebnisse zu erreichen und manchmal kann die Güte negativ von dem gewählten Verfahren beeinflusst werden.  \cite{weiss91}
\section{Algorithmen}
\subsection{Bayes-Klassifikatoren}
\subsubsection{Beschreibung:}
Bei der Bayes-Klassifikation wird auf die mathematische Grundlage der Wahrscheinlichkeitsberechnung der einzelnen Klassen aufgebaut. Diese folgen dem \textit{Satz von Bayes} , welcher mit der Formel \[P(X|Y) = \frac{P(Y|X)\ P(X)}{P(Y)}\]\\ beschrieben werden kann. 

Durch diese Formel kann die Wahrscheinlichkeit, dass ein unbekanntes Objekt einer Klasse angehört, berechnet werden. Die Wahrscheinlichkeit \textit{a posteriori} einer Hypothese X kann unter der Annahme von einer anderen Hypothese Y und anhand der Wahrscheinlichkeiten von X und Y erklärt werden. \cite{brei84,mitch97}

\subsubsection{Algorithmus}
Dieser Algorithmus wird \textit{naiver Bayes-Klassifikator} genannt. Seine Funktionsweise ist, dass ein unbekanntes Objekt einer Klasse bei der die Wahrscheinlichkeit für die bestimmte Klasse am höchsten ist, zugeordnet wird. Die Formel dazu lautet: \\

\(C_i\): Klasse\\

\(x\): Unbekanntes Objekt\\

\[P(C_i|x) = \frac{P(x|C_i)\ P(C_i)}{P(x)}\]\\

Das Objekt wird nur dann einer Klasse zugewiesen, wenn die Wahrscheinlichkeit (\(P(C_i|x)\)) ein Maximum darstellt. Die Wahrscheinlichkeit für jede einzelne Klasse ist immer gleich. Dadurch muss nur der Zähler im Bruch maximiert werden und dadurch entsteht eine neue Regel welche lautet:

\[arg\max\limits_{C_i \in \{C_1,\dotsc,C_k \}}\ P(x|C_i)\ P(C_i) \]\\

Die Wahrscheinlichkeit der einzelnen Klassen kann anhand der Trainingsdaten geschätzt werden. Mit Hilfe nachfolgender Formel kann die Anzahl der Trainingsobjekte pro Klasse bestimmt werden:\\


\[P(C_i) = \frac{|\{o \in T| o \in C_i\}|}{|T|}\] 

Um die Wahrscheinlichkeit der Zuordnung zu den Klassen schätzen zu können muss die Annahme getroffen werden, dass der \textit{naiver Bayes-Klassifikator} die Attribute der einzelnen Objekte als unabhängig betrachtet. Das bedeutet dass sich die Merkmale bzw. die Eigenschaften nicht gegenseitig behindern. Daher lässt sich dann die Klassenspezifische Wahrscheinlichkeit wie folgt berechnen:\\


\[P(x_j|C_i) = \prod_{j=1}^d{P(x_j|C_i)}\]

Dabei lässt sich die wahre Wahrscheinlichkeit der Objekte mit Hilfe der Trainingsdaten berechnen bzw. abschätzen.\\


\[P(x_j|C_i) = \frac{|\{y \in T | y \in C_i \wedge y_j = x_j\}|}{|\{y \in T |y \in C_i\}|}\]\\


\cite{brei84,mitch97}
\subsubsection{Zusammenfassung}
Der \textit{naive Bayes-Klassifikator} geht grundsätzlich von dem Satz von Bayes aus und verwendet diesen Algorithmus um Objekte einer Klasse zuzuordnen. Er beruht auf dem Prinzip der Unabhängigkeit von Eigenschaften, da sonst die Wahrscheinlichkeiten nicht vollständig aus den Testdaten berechnet werden können. Auch ist anzumerken, dass dieser Algorithmus nicht sehr effizient im Vergleich zur Anzahl der Trainingsdaten fungiert. \cite{brei84,mitch97}

\subsection{Entscheidungsbäume}
\subsubsection{Beschreibung} 
Bei den Entscheidungsbäumen läuft die Klassifikation aufgrund von Einteilungen der Objekte anhand von Baumstrukturen ab und so kann eine hierarchische Klassenordnung erzeugt werden. Die einzelnen Knoten repräsentieren die Klassen, welche zu Beginn leer sind oder enthalten diverse Tests, die einem bestimmten Attribut zugeordnet sind. Doch in der Praxis sind die  Attribute der einzelnen Objekte nicht eindeutig zuordenbar und so kann es vorkommen, dass manche Objekte mehrfach in verschieden Klassen vorhanden sind. \\
Um ein Objekt mit dieser Methode zu klassifizieren, wird bei der Wurzel des Baumes begonnen und dann jedes Attribut pro Schritt durchgegangen, bis die gesamten Attribute in Klassen eingeteilt sind. Dies wird wiederholt bis die Objekte mit deren Attribute den richtigen Blättern zugewiesen sind.\cite{brei84,mitch97}


\subsubsection{Algorithmus}

Es gibt nicht nur einen Algorithmus für Entscheidungsbäume, sondern nur eine Richtlinie wie so ein solcher Algorithmus auszusehen hat und folgt meistens einem generalisierten Schema:

\begin{enumerate}
	\item Es wird definiert, dass die Wurzel (hier als \(K\) bezeichnet) und der dazugehörige Baum (bezeichnet als \(B\) ) mit der Menge der Trainingsdaten (hier \(T\)) die Ausgangssituation bildet.\\
	\item Es wird das Attribut (hier 	\(A_i\)) einem Test zugeordnet, welcher die Testmenge am besten in Objekte aufteilt und daraus die Teilmengen generiert (hier \(T_1,\dotsc,T_m\)).\\	
	\item Die ganze Testmenge wird  nach dem ausgewählten Test auf die Teilmengen hier \(T_j\) aufspaltet und daraus ein Knoten (\(K_j\)) als Unterordnung vom Wurzelknoten generiert.\\	
	\item Für alle abhängigen Knoten, welche alle derselben Klasse angehören, wird ein Blatt im Baum erzeugt. Andernfalls wird weiter rekursiv durch den Baum gegangen und weiter aufgeteilt bis keine Zuordnung mehr möglich ist\\
	
\end{enumerate} 


Die Aufspaltung in die Teilmengen geschieht nach dem Prinzip eines Tests, welcher am besten die Testdaten aufspaltet.  Damit stellt sich die Frage wie die Qualität von einem solchen Test bewertet werden kann. Der erste Ansatz ist das Prinzip der Reinheit der Daten; das bedeutet, dass die Teilmengen nur Objekte von einer Klasse beinhalten. Ein gutes Maß ist die Entropie, die angibt wie groß die Unordnung in einer Menge ist.\cite{brei84,mitch97}\\
 Die Formel lautet:\\

\[entropie(T) = -\displaystyle\sum_{i=1}^k p_i \log_2 p_i\]\\


\(p_i\) ist die Wahrscheinlichkeit mit der ein Objekt, welches einer Teilmenge angehört in einer Klasse vorhanden ist. Diese Wahrscheinlichkeit lässt sich anhand der Trainingsdaten abschätzen:\\

\[p_i = \frac{|\{x \in T| x \in C_i\}|}{|T|}\] \\


Mit Hilfe der Berechnung der Entropie kann nun ein bedeutenderes Maß berechnet werden, welches sich \textit{Informationsgewinn (gain)} nennt und  die Abnahme der Entropie während eines ganzen Teilungsschrittes beschreibt. Die Formel dafür lautet: \\


\[gain(T,A) = entropie(T) - \displaystyle\sum_{i=1}^k \frac{|T_j|}{|T|} entropie(T) \]\\

Durch die Berechnung von dem \textit{gain} kann nun bestimmt werden wie der Algorithmus die Testdaten  aufteilt. Durch Verfeinerung  der Methode (\textit{gain}) kann durch die \textit{gain ratio} eine Kombination aus \textit{split info} und dem \textit{gain}  wie folgt mittels Formeln beschrieben werden: \\

 \begin{enumerate}
	 \item \[split\ info(T,A) = - \displaystyle\sum_{i=1}^k \frac{|T_j|}{|T|} \log_2 \frac{|T_j|}{|T|}\]
		\item \[gain\ ratio(T,A) = \frac{gain (T,A)}{split\ info(T,A)}\]\\
 \end{enumerate} 

Um gewisse begünstigte Aufteilungen zu verbieten wird für die \textit{gain ratio} ein Schwellenwert festgelegt.



Es existiert neben der \textit{gain ratio} auch ein weiteres Maß, welches sich \textit{Gini-Index} nennt. Dieses Maß ist einfach zu bestimmen und liefert dennoch gut vergleichbare Ergebnisse. Dieser Index sich lässt nach einer einfachen Formel bestimmen: \\

\[gini(T) = 1 - \displaystyle\sum_{i=1}^k p_i^2 \]\\


Mit Hilfe dieser Formel lässt sich der \textit{Gini-Index} für die Gesamtheit der Klassen berechnen.Die einzelnen Partitionen werden als \(T_n\) bezeichnet. Hilfreich ist diesbezüglich folgende Formel:\\


\[gini(T_1,\dotsc,T_m =  \displaystyle\sum_{i=j}^m \frac{|T_j|}{T}\ gini(T_i)\]\\


Nachdem mit den oben beschriebenen Strategien ein geeigneter Entscheidungsbaum aufgebaut worden ist, können alle Objekte anhand deren Attribute einer bestimmten Klasse zugeordnet werden. \cite{brei84,mitch97}


\subsubsection{Overfitting} 
Ein Entscheidungsbaum kann mithilfe der Trainingsdaten korrekt aufgebaut werden. Aber es ist möglich, dass neue Daten nicht mehr vollständig klassifiziert werden können. Dadurch verschlechtert sich die Güte der Daten und es entsteht dann ein weniger komplexer Baum. Dieser Effekt wird dann als \textit{Overfitting} bezeichnet. \cite{mitch97}\\

 Fast alle Algorithmen implementieren eines der beiden Verfahren, mit welchen das \textit{Overfitting} reduziert werden kann:\\
\begin{itemize}
	\item Der Algorithmus wird vorher schon gestoppt, bevor ein \textit{Overfitting} zustande kommen kann. So wird vermieden, dass die Klassifikationsgüte zu stark verschlechtert wird. Dieser Vorgang wird als \textit{pre-pruning} bezeichnet und ist weniger verbreitet, da es schwer ist zu bestimmen wann der Aufbau des Entscheidungsbaums gestoppt werden muss.
	
	\item Der Entscheidungsbaum wird fertig aufgebaut und dann vereinfacht, indem Knoten durch Blätter ersetzt werden. Diese Methode wird als \textit{post-pruning} bezeichnet und ist einfacher zum Ausführen, da bereits ein Entscheidungsbaum vorliegt. 
\end{itemize}
\cite{mitch97}

\subsubsection{Zusammenfassung:}
Die Entscheidungsbäume sind eine komfortable Methode um Daten zu klassifizieren, da deren Aufbau einfach gestaltet ist. Die meisten Algorithmen sind binär ausgeführt, da im Zusammenhang mit Entscheidungsbäumen jede Wurzel zwei Kindknoten oder Blätter besitzt. Die Aufteilung in Trainingsdaten und Testdaten erfolgt vor der eigentlichen Berechnung. Diese Aufteilung ist das Grundkonzept von Entscheidungsbäumen. Dabei werden verschiedene Methoden implementiert wie oben bereits beschrieben. \\
Der eigentliche entscheidende Schritt dabei ist das Pruning, welches den Baum so optimiert, das die Güte der Klassifikation ausreichend ist. Ein aussagekräftiges Kriterium ist auch die Anzahl der Attribute welche ein Objekt besitzt. Es ist dabei wichtig dass der Entscheidungsbaum mit genügend Trainingsdaten aufgebaut wird, da sonst die Güte darunter leidet.\\ \cite{brei84}

\subsection{(\textit{k})-Nächste-Nachbarn-Klassifikatoren} 

\subsubsection{Beschreibung:}
Diese Methode ist auch bei \nameref{Clustering} bekannt und macht sich die Distanzberechnung der einzelnen Objekte zu Nutze. Durch die \textit{Nähe} der einzelnen Nachbarn werden die einzelnen Objekte bestimmten Klassen zugeordnet. \cite{brei84, mitch97}

\subsubsection{Algorithmus}
Die Methode beschreibt das Verfahren bei der unbekannte Objekte anhand der Distanz zu den Trainingsobjekten einer Klasse zugeordnet werden können.
Mit dieser Formel lässt sich die Vorgangsweise beschreiben: \\


\[c(x) = c \bigg( \min\limits_{y \in T} dist(x,y) \bigg)\]\\

Dabei bezieht sich das \(dist(x,y) \) auf die Euklidische Distanz, welche sich nach folgender Formel berechnet: \[\sqrt{\displaystyle\sum_{i=1}^1 (x_i - y_j)^2}\] \\

Eine andere Möglichkeit ist nicht nur die unmittelbaren Nachbarn sondern auch weiter entfernte Nachbarn für die Berechnung heranzuziehen und dadurch die Qualität zu steigern. Dabei wird ein unbekanntes Objekt einer Klasse zugeordnet. Die benachbarten Objekte gehören der jeweiligen Klasse an. Die Nächsten Nachbarn werden als \(y_n\) bezeichnet und können durch folgende Formel berechnet werden:\\

\[c(x) = \max\limits_{C_i \in C}\ \displaystyle\sum_{j=1}^k \delta (C_i,c(y_i))\]
\cite{brei84, mitch97}
\subsubsection{Zusammenfassung:}
Bei den (\textit{k})-Nächste-Nachbarn-Klassifikatoren werden Objekte anhand von Nachbarschaften bestimmten Klassen zugeordnet. Dabei sind die einzelnen Klassifikationsschritte unabhängig voneinander, da sich Nachbarn gegenseitig nicht beeinflussen. Die Wahl der richtigen Distanzfunktion ist entscheidend wie gut der Algorithmus arbeitet. 
\section{Zusammenfassung und Ausblick}
Die Klassifikation ist neben den Clustering eine wichtige Methode Objekte in Klassen einzuteilen. Bei der Klassifikation werden die Daten mithilfe verschiedener Methoden in Trainingsdaten und Testdaten aufgeteilt und anhand von den Testdaten eindeutig einer Klasse zugeordnet. Das wichtigste bei der Klassifikation ist die richtige Wahl der Anzahl von den Trainingsdaten. Nur so ist sichergestellt, dass eine ausreichende Klassifikationsgüte erreicht wird.\\
In Zukunft wird sich an den hier vorgestellten Prinzipien wenig ändern, da diese effizient und auch performant sind. Daher müssen in Zukunft neue noch bessere Algorithmen gefunden werden, welche noch größere und noch komplexere Daten klassifizieren können. 





 
